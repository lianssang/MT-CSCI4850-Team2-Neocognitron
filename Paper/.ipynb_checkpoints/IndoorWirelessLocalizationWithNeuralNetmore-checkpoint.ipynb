{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indoor Wireless Localization with Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Manoj Basnet, Steven Hearne, Lian Sang, Gregory Wagner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABSTRACT:\n",
    "    \n",
    "The next generation of GPS like navigation lies within the doorstep of modern buildings. With the use of mobile devices and the trending of user-friendly applications, indoor wireless localization is a possibility in today's society. By taking advantages over Recieved Signal Strength (RSS) of WiFi signals and fingerprint database, the existance of GPS-like indoor is near in the future. However, the trouble of indoor localization is that the RSS values on the reference device and target device are not quite the same, or exact, therefore it has cause errors in localization. To capture and minimize the errors, a method of multilayer network will be used. In order to proceed this method, fingerprinting a number of locations that one desire within the indoor space is required. As mentioned that the a reference device is needed, therefore a WiFi equipped laptop is set up for each location to be fingerprinted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index Terms - Indoor localization; wireless networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. INTRODUCTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GPS has been a very functional tool that provides many beneficial factors for society from advancing technology of auto-pilot vehicles to calculation on movements of the Earth's surface, as to indoor localization the potential may also be numerous, especially for civilians. Knowing that many buildings in today's populated cities, such as residential houses and commercial zones are equipped with wireless technology, by taking a step further to advancement of navigation could possibly be another breakthrough in the waiting. Imagine a single tap away from navigating indoor without the help of another person except for a turn-by-turn visualization mapping that feeds out, the benefit can be viewed quite substantial to several fields, whether it is for public safety or private investment. With the capability that indoor wireless localization holds, the technology extends the nature of safety by monitoring senior citizens and children from endangerment. As for luxurious use of the localization technology, many commercially-based companies may lure in consumers based on their current location by the user's shopping interests. It is a win-win situation for consumers and merchandisers with the help of indoor localization technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. BACKGROUND:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As unfortunate as today's GPS systems are not meant to be used for indoor environment, it is time that the tech community introduce a new method of wireless localization for inside buildings. Starting with the selection of signal, which is a crucial drawbacks of GPS for indoor, there are several signal types that can accommodate indoor localization: common ones like FM radio that got used in [1] and the used of visible light in [2], and a potential signal that could extend GPS signal with pseudolite in [3]. Given that these various types of signal could possibly extend the navigation dream, WiFi signal that is used in [4] could potentially be the best candidate for this project. Since WiFi signals are being used nearly everywhere in our modernize environment, it is ideally a smart choice also considering the fact that a user's device, such as a smartphone or tablet, is already equipped with built-in WiFi capable hardware.\n",
    "After deciding the systematic signals for wirelesss localization, techniques and methods are w When it comes to the localization of indoor wireless, there is also a selection for the techniques in which that can be done. Therefore, just like selecting a signal type, it can be such a bold move to choose any type of wireless method of navigation to alternate an indoor version of GPS. This is because there are several techniques for wireless indoor localization, which can be found in [5], for each with different drawbacks. As for the convenience of measurement issue, mapping methods are required due to the conversion of physical measurements to environmental locations. selecting an appropriate method of techniques is severely important. Depending on the different types of mapping the techniques are varies. According to [4], the most representable type of mapping would be geomatric mapping due to the complexity of the environment, therefore the specific mapping will require fingerprinting methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III METHODS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA:\n",
    "\n",
    "An appropriate step to approach this project would be to obtain some form of data sets. Since the study is dealing with WiFi localization, therefore some very important key words (numerical data) such as: number of scans, training vectors, locations, and wireless access points (APs), etc. are nescessary to be trained using neural network. Depending on the Neural Network Model one choose to exercise, the values previously listed are to be adjusted accordingly. The training data for the Neural Net will need to be set up in a dataset that consists of the label with feature vectors. This dataset for example should look something like [loc 0 - number of choice], and its features should be RSSI values from the APs. The difficult part to this dataset is that one should plan the number of locations according to the environment and figuring out the count of APs that is necessary to satisfy the project. Here is an example vector:\n",
    "\n",
    " AP1  | AP2 | AP3  | AP4 | AP5 |  location  \n",
    " ----:|----:| ----:|----:|----:|----------:|\n",
    " -50  | -74 | -66  | -55 | -60 |0          |\n",
    "\n",
    "As for raw data, using WifiInfoView.exe program should do the trick. If one is on a Linux machine, then it is necessary to 'wine' to run a Windows executable. Keep in mind that if it envolves the use of Jupyter notebook and while being on a remote system, then WiFi information being collected is not from ones machine. For the db_wifiinfo.bat and db_wifi_bash.ipynb files, these are for Windows/Linux respectively and will run the .exe program a number of times to produce scans of any location one choose to be. For this, also keep in mind that a robust data set is data that is taken over different periods of time, this is because of the nature of signal interference in APs. However, the tendency for the scans to produce NULL data where a signal has been momentarily lost, it is a good idea to get at least 500 scans per desired location for the Net. In provided examples, the data is taken continously (1 - max_loc_scans). In this experiment the data was initially taken and spread into vector files in order to find an average of 10 scans, to deal with some of the signal loss that will inevitably occur.  We found that this averaging had a severe effect on the variance the data should have represented to train the network properly.  In this case, one should take 500 or more scans at each location moving from location to different location and remember to space them out over time and allow small variance in time for the raw data. By following this method, one should now be able to take all the raw data that is neccessary for this study. \n",
    "\n",
    "As for processing the data that is obtained, ensure that the raw data is set up in location folders, in this case (loc_1_MAXLOC), in this example vector sub folders (vec_1-MAXVEC) exist but are not required, and a number of scans likely five to ten scans (dbXX.csv which XX is 1-MAXSCANS) inside the vector folders. The scans can be allocated (1-MAXSCANS) in each loaction folder.  If data is sorted as in this experiment, reusing the data_to_vector.ipynb to sort the vector files should be an appropriate choice. One should note that clean_loc_data is a bash file for removing vec_X folders from each loc_X folder quickly.  One could alter these simple scripting tools to thier desired setup.\n",
    "\n",
    "Once the files are correctly setup, one should modify the number of key words inside of builddata.ipynb then should run the script to produce a training set for the Neural Net.\n",
    "\n",
    "A set of testing data should be taken from each location in about 20 scans, or however many it takes to have at least a few vectors that do not have nan values.  These can be sorted in much the same way as the training locations.\n",
    "\n",
    "It should be noted that 3000 scans were taken for the three locations total 1000 scans at each location, and only around 1500 provided valid training vectors for the network.  So one can conclude the raw data mechanisms are about 50% efficeint.\n",
    "\n",
    "#### PCA:\n",
    "\n",
    "In our PCA we are able to get a better understanding of how the Neural Network will view our data and make decision boundries.  The data is read in along with the planned testing locations, we then use Singular Value Decomposition to find the variance attributed to each feature.  Then we use the first two features, where approximately 54% of our variance lies, and plot our data along these as basis vectors.  In our PCA we found fairly clear descision boundries that could be handled by a Multi-layered Neural Network with non-linear activation functions.  Our testing data was also included, to see if our network was able to group the testing and training data similarly.  We found that our network would be able to do so.\n",
    "\n",
    "#### Network:\n",
    "The neural network needed for the wireless localization is fairly small and simple Multi-Layered Perceptron(MLP) with two hidden layers each with 64 hidden units. The non-linear discriminant functions used for the first and second hidden layer were ReLU and Sigmoid respectively with bias weight initilized to 0.01 for avoiding zero bias. The reason behind using those functions is it seemed to be the most reliable for our data set. Since, we are intersted in classifying 3 locations, the loss funtion would be categorical-cross entropy. Hence, the natural activation function for the output layer would be softmax. A deeper net is always preferred as compared to wider net. That's why MLP with two hidden layers are used in our net. Ideally, any net with a single hidden layer would be able to classify the datasets.\n",
    "Optimzer Adam is widely used in the state of art applications that's why it became natural choice for us too.\n",
    "\n",
    "Our input data has eight feature vectors each feature extracted from a shared AP among all three locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. RESULTS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 % accuracy and loss of 0.0003041 for both train and validation data were observed within just 5 epochs( 27.55 seconds) with a MLP composed of two hidden layers each with 64 hidden units and with the batch size of 56. This net is able to classify the 36 random location data into three location category with 100% accuracy. The simpler network topology with only 4931 trainable parameters , just 5 epochs to get 100% validation and training accuracy, minimal training time around 27.55 s, tendency to use minimal features (most significant APs inside the room producing strongest RSS) and 100% test accuracy are the most appealing feature of this network which make this net strongest contender for efficient wireless indoor localization in the current state of art. Temporal variance of the RSS signals is problematic itself for fingerprinting the radio map. However, this method produces 100% accuracy on classifying RSS signals taken at different time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V. DISCUSSION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 53% of variance accounted for first 2 principal components. The dimensionality reduction technique might cost the useful information to be thrown away. As depicted from PCA plot, Almost 96% variance accounted for first six principal components. Therefore, we can not throw away first six PCAs. Apart from some outliers, most of the data are clusterd around three means (refering to three different locations data) with different variances( spreading of clusters). If we discard some outliers from each class, we might be able to use MLP with linear activation. However, Not a single data should be discarded in order to classify oddly distributed data during the testing. Therefore, for the perfect classification, a MLP with a hidden layer with some non linear discriminant function such as ReLU or Sigmoid is recommended from PCA analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 % accuracy and loss of 0.0003041 for both train and validation data were observed within just 5 epochs( 27.55 seconds) with a MLP composed of two hidden layers each with 64 hidden units and with the batch size of 56. Ideally, a MLP with single hidden layer would be able to classify the training data. However, a deeper net is always preferred over the wider one. This net is very efficient and simpler as compared to other current state of art application for localization as depicted in accuracy and loss plot.\n",
    "\n",
    "The real challenge was how the net gonna perform for the new set of test data that were not trained. Total of 36 test data, 14 from location 1, 11 each from location 2 and location 3 were captured on different day at different time knowing that the temporal variance of RSS would be there. Our net was 100 % accurate to distinguish between those locations data provided that the test data were gone for the same preprocessing and curve fitting as the train data did. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are considerably various factors that might affects our data: 1) the indoor environment such as room topology, crowd might cause  Wi-Fi signals to be attenuated, reflected and suffered from multipath fading. That's why from the same AP at different scans,the same  RSSI values might differ for the same location. The larger the number of scans, the more variance of the RSSI could be captured. 2) Wifi-Module: Since there's no uniform standard followed by different vendors and also 802.11 protocols do not precisely define how the RSS values should be interpreted. Therefore, there might be discrepencies using different devices for fingerprinting and testing. The solution for this is train the model with varities of devices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During each scan, the number of scanned APs might be different due to various causes as explained above. The strongest first eight RSS signals from eight shared APs among three locations were our useful data. If the scan missed any one of the shared AP,then the RSS inforamtion of that scan would be  automatically discarded by our code. For resolving this issue, we might use only APs inside the room which are very strong as compared to faraway APs. Since, the RSS obtained from faraway AP is relatively weak and easily perturbed and does not have enough contribution towards localization. In this way, the proposed NN can be made more robust and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
